import json
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

def analyze_speech_similarity(json_file_path, output_json_path='analysis_results.json'):
    """
    íšŒì˜ë¡ JSON íŒŒì¼ì„ ì½ì–´, ì „ë¬¸ìœ„ì› ë³´ê³  ë‚´ìš©ê³¼
    ë‹¤ë¥¸ ì˜ì›ë“¤ì˜ ë°œì–¸ ê°„ì˜ ì˜ë¯¸ ìœ ì‚¬ë„ë¥¼ ë¶„ì„í•˜ê³  ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    """
    
    # 1. ë°ì´í„° ë¡œë“œ
    try:
        with open(json_file_path, 'r', encoding='utf-8') as f:
            speeches = json.load(f)
    except FileNotFoundError:
        print(f"ì˜¤ë¥˜: '{json_file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    except Exception as e:
        print(f"íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return

    # 2. AI ì„ë² ë”© ëª¨ë¸ ë¡œë“œ (í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸)
    try:
        model = SentenceTransformer('jhgan/ko-sbert-nli')
        print("AI ì„ë² ë”© ëª¨ë¸(ko-sbert-nli) ë¡œë“œ ì¤‘...")
    except Exception as e:
        print(f"ko-sbert-nli ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨. ëŒ€ì²´ ëª¨ë¸(ë‹¤êµ­ì–´)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. (ì˜¤ë¥˜: {e})")
        model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

    # 3. 'ë²•ì•ˆ ë‚´ìš© ë¬¸ì„œ' (ì „ë¬¸ìœ„ì› ë³´ê³ ) ì¶”ì¶œ
    expert_reports = []
    for speech in speeches:
        member_name = speech.get('member_name', '')
        if 'ì „ë¬¸ìœ„ì›' in member_name:
            expert_reports.append({
                'speech_id': speech['speech_id'],
                'bills_key': speech['bills'],
                'description': speech['speech_text']
            })

    if not expert_reports:
        print("ë¶„ì„ ê¸°ì¤€ì´ ë  'ì „ë¬¸ìœ„ì›'ì˜ ë°œì–¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 4. 'ë²•ì•ˆ ë‚´ìš© ë¬¸ì„œ'ì— ëŒ€í•œ ì„ë² ë”© ë¯¸ë¦¬ ê³„ì‚°
    print(f"ì „ë¬¸ìœ„ì› ë³´ê³ ì„œ {len(expert_reports)}ê±´ì˜ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤...")
    report_descriptions = [report['description'] for report in expert_reports]
    report_embeddings = model.encode(report_descriptions)

    # 5. 'ì˜ì› ë°œì–¸' (ì¿¼ë¦¬)ì„ ë¶„ì„í•˜ì—¬ ê°€ì¥ ìœ ì‚¬í•œ 'ë²•ì•ˆ ë‚´ìš©' ë§¤ì¹­
    print("ì˜ì› ë°œì–¸ì„ ë¶„ì„í•˜ê³  ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤...")
    analysis_results = []
    total_speeches = len(speeches)
    
    for i, speech in enumerate(speeches):
        member_name = speech.get('member_name', '')
        speech_text = speech['speech_text']

        # ì „ë¬¸ìœ„ì› ë³¸ì¸ ë°œì–¸ ë° ë„ˆë¬´ ì§§ì€ ë°œì–¸(ì˜ˆ: "ì˜ˆ.")ì€ ë¶„ì„ì—ì„œ ì œì™¸
        if 'ì „ë¬¸ìœ„ì›' in member_name or len(speech_text) < 30:
            continue
            
        # ì§„í–‰ ìƒíƒœ í‘œì‹œ (ì„ íƒ ì‚¬í•­)
        # if (i + 1) % 100 == 0:
        #     print(f"  ì§„í–‰ ì¤‘: {i+1} / {total_speeches} ë°œì–¸ ì²˜ë¦¬ ì¤‘...")

        # í˜„ì¬ ë°œì–¸(ì¿¼ë¦¬)ì˜ ì„ë² ë”© ìƒì„±
        speech_embedding = model.encode([speech_text])

        # ëª¨ë“  'ë²•ì•ˆ ë‚´ìš© ë¬¸ì„œ'ì™€ì˜ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = cosine_similarity(speech_embedding, report_embeddings)

        # ê°€ì¥ ì ìˆ˜ê°€ ë†’ì€ ë§¤ì¹­ í•­ëª© ì°¾ê¸°
        best_match_index = np.argmax(similarities)
        best_score = similarities[0][best_match_index]
        matched_report = expert_reports[best_match_index]

        analysis_results.append({
            'speech_id': speech['speech_id'],
            'member_name': member_name,
            'speech_text': speech_text, # ìŠ¤ë‹ˆí« ëŒ€ì‹  ì „ì²´ í…ìŠ¤íŠ¸ ì €ì¥
            'score': float(best_score),
            'matched_report_id': matched_report['speech_id'],
            'matched_bills': matched_report['bills_key'].replace('\n', ' | ')
        })

    # 6. ê²°ê³¼ë¥¼ ìœ ì‚¬ë„ ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
    analysis_results.sort(key=lambda x: x['score'], reverse=True)
    
    # 7. *** [ì¶”ê°€ëœ ì½”ë“œ] ***
    #    ì „ì²´ ë¶„ì„ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
    try:
        with open(output_json_path, 'w', encoding='utf-8') as f:
            json.dump(analysis_results, f, ensure_ascii=False, indent=4)
        print(f"\nâœ… ë¶„ì„ ê²°ê³¼ ì´ {len(analysis_results)}ê±´ì„ '{output_json_path}' íŒŒì¼ë¡œ ì„±ê³µì ìœ¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ë¶„ì„ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")


    # 8. ì½˜ì†”ì— ìƒìœ„ ê²°ê³¼ ì¼ë¶€ ì¶œë ¥
    print("\n--- ë¶„ì„ ê²°ê³¼ (ìœ ì‚¬ë„ ìƒìœ„ 10ê±´) ---")
    print("-" * 70)

    for result in analysis_results[:10]:
        print(f"ğŸ—£ï¸  ë°œì–¸ ID: {result['speech_id']} (ë°œì–¸ì: {result['member_name']})")
        print(f"   ë‚´ìš©: \"{result['speech_text'][:80]}...\"")
        print(f"   â¡ï¸  ë§¤ì¹­ ë²•ì•ˆ (ìœ ì‚¬ë„: {result['score']:.4f}):")
        print(f"       {result['matched_bills']} (ê¸°ì¤€ ë³´ê³ ì„œ ID: {result['matched_report_id']})")
        print("-" * 70)


# --- ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ---
if __name__ == "__main__":
    # ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ì¼í•œ ìœ„ì¹˜ì— 'speeches_meeting_50242.json' íŒŒì¼ì´ ìˆë‹¤ê³  ê°€ì •
    # ì €ì¥ë  íŒŒì¼ëª…ì€ 'analysis_results.json' ì…ë‹ˆë‹¤.
    analyze_speech_similarity(
        json_file_path='speeches_meeting_50242.json',
        output_json_path='analysis_results.json'
    )