import json
from sentence_transformers import SentenceTransformer
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import time

# --- ì„¤ì • ---
EMBEDDING_FILE = 'report_embeddings.npy'
METADATA_FILE = 'report_metadata.json'
MODEL_NAME = 'jhgan/ko-sbert-nli'  # 1ë²ˆ ìŠ¤í¬ë¦½íŠ¸ì™€ ë°˜ë“œì‹œ ë™ì¼í•œ ëª¨ë¸ ì‚¬ìš©
TOP_K = 3  # ìƒìœ„ ëª‡ ê°œê¹Œì§€ í‘œì‹œí• ì§€
# -----------

def load_index():
    """ ì €ì¥ëœ ì„ë² ë”©ê³¼ ë©”íƒ€ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤. """
    try:
        embeddings = np.load(EMBEDDING_FILE)
        with open(METADATA_FILE, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        
        if len(embeddings) != len(metadata):
            print("ì˜¤ë¥˜: ì„ë² ë”© íŒŒì¼ê³¼ ë©”íƒ€ë°ì´í„° íŒŒì¼ì˜ ê°œìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return None, None
            
        return embeddings, metadata
    except FileNotFoundError:
        print(f"ì˜¤ë¥˜: '{EMBEDDING_FILE}' ë˜ëŠ” '{METADATA_FILE}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ë¨¼ì € 'embeddings_generator.py' ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•´ ì£¼ì„¸ìš”.")
        return None, None
    except Exception as e:
        print(f"ì¸ë±ìŠ¤ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, None

def search_documents(query, model, db_embeddings, db_metadata, top_k):
    """
    ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì„ë² ë”©í•˜ê³  DBì™€ ë¹„êµí•˜ì—¬ ìƒìœ„ Kê°œ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # 1. ê²€ìƒ‰ ì¿¼ë¦¬ ì„ë² ë”© (1ê°œë§Œ)
    query_embedding = model.encode([query])
    
    # 2. DB ì„ë² ë”©ê³¼ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    similarities = cosine_similarity(query_embedding, db_embeddings)
    
    # 3. ìœ ì‚¬ë„ ì ìˆ˜ê°€ ë†’ì€ ìˆœì„œë¡œ ì¸ë±ìŠ¤ ì •ë ¬
    # argsortëŠ” ì˜¤ë¦„ì°¨ìˆœì´ë¯€ë¡œ [:-top_k-1:-1]ì„ ì‚¬ìš©í•´ ìƒìœ„ Kê°œë¥¼ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì¶”ì¶œ
    top_k_indices = np.argsort(similarities[0])[:-top_k-1:-1]
    
    # 4. ê²°ê³¼ ë°˜í™˜
    results = []
    for idx in top_k_indices:
        results.append({
            'score': similarities[0][idx],
            'metadata': db_metadata[idx]
        })
    return results

# --- ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ---
if __name__ == "__main__":
    # 1. ëª¨ë¸ ë° ì¸ë±ìŠ¤ ë¡œë“œ (ìµœì´ˆ 1íšŒ)
    print(f"'{MODEL_NAME}' ëª¨ë¸ ë¡œë“œ ì¤‘...")
    start_time = time.time()
    model = SentenceTransformer(MODEL_NAME)
    print(f"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ. (ì†Œìš” ì‹œê°„: {time.time() - start_time:.2f}ì´ˆ)")

    print("ì €ì¥ëœ ì„ë² ë”© ì¸ë±ìŠ¤ ë¡œë“œ ì¤‘...")
    db_embeddings, db_metadata = load_index()
    
    if db_embeddings is not None:
        print(f"âœ… ì´ {len(db_embeddings)}ê°œì˜ ë²•ì•ˆ ë³´ê³ ì„œ ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ.")
        
        # 2. ëŒ€í™”í˜• ê²€ìƒ‰ ë£¨í”„
        while True:
            try:
                # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
                query = input("\nğŸ” ê²€ìƒ‰í•  ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ì…ë ¥): ")
                if query.lower() == 'exit':
                    print("ê²€ìƒ‰ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break
                if len(query) < 2:
                    print("ê²€ìƒ‰ì–´ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤.")
                    continue
                    
                # 3. ê²€ìƒ‰ ìˆ˜í–‰
                start_time = time.time()
                search_results = search_documents(query, model, db_embeddings, db_metadata, TOP_K)
                end_time = time.time()
                
                print(f"\n--- ê²€ìƒ‰ ê²°ê³¼ (ì†Œìš” ì‹œê°„: {end_time - start_time:.4f}ì´ˆ) ---")
                
                # 4. ê²°ê³¼ ì¶œë ¥
                for i, result in enumerate(search_results):
                    meta = result['metadata']
                    print(f"\nğŸ¥‡ [ìœ ì‚¬ë„ {result['score']:.4f}] - {i+1}ìœ„")
                    print(f"   ë²•ì•ˆ: {meta['bills']}")
                    print(f"   ë³´ê³ ì: {meta['member_name']} (ID: {meta['speech_id']})")
                    print(f"   ë‚´ìš©: {meta['speech_text'][:150]}...")

            except KeyboardInterrupt:
                print("\nê²€ìƒ‰ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            except Exception as e:
                print(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")